{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as e\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import math\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,x,gradient,hessian,idxs,subsample_cols = 1, min_leaf = 1, min_child_weight = 1, \n",
    "                 depth = 2, lambda_ = 1, gamma = 1, eps = 0.01):\n",
    "        self.x = x\n",
    "        self.gradient = gradient\n",
    "        self.hessian = hessian\n",
    "        self.idxs = idxs\n",
    "        self.subsample_cols = subsample_cols\n",
    "        self.min_leaf = min_leaf\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.depth = depth\n",
    "        self.lambda_ = lambda_\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.rows_cnt = len(idxs)\n",
    "        self.col_count = x.shape[1]\n",
    "        \n",
    "        # print(self.idxs)\n",
    "        # print(gradient[self.idxs])\n",
    "        # Select a subspace of attributes.\n",
    "        self.column_subsample = np.random.permutation(self.col_count)[:round(self.subsample_cols*self.col_count)]\n",
    "        \n",
    "        self.val = self.calc_val(self.gradient[self.idxs],self.hessian[self.idxs])\n",
    "        \n",
    "        self.score = float('-inf')\n",
    "        self.find_split()\n",
    "        # print(self.is_leaf)\n",
    "        \n",
    "    def calc_val(self,gradient,hessian):\n",
    "        # Calculate the optimal value of a leaf.\n",
    "        value = np.sum(gradient)/(np.sum(hessian)+self.lambda_)\n",
    "        value = value*-1\n",
    "        return value\n",
    "\n",
    "    def find_split(self):\n",
    "        # Scans through every column & calculates the best split point. If node is split, \n",
    "        # two other nodes are created accordingly. If no split is better then we just return \n",
    "        # without making splits.\n",
    "        \n",
    "        for col in self.column_subsample:\n",
    "            self.find_greedy_split(col)\n",
    "        \n",
    "        # for col in self.column_subsample:\n",
    "        #     self.find_approx_split(col)\n",
    "            \n",
    "                \n",
    "        if (self.is_leaf()):\n",
    "            return\n",
    "        \n",
    "        split_col = self.split_col()\n",
    "        \n",
    "        lhs = np.nonzero(split_col <= self.split)[0]\n",
    "        rhs = np.nonzero(split_col > self.split)[0]\n",
    "        \n",
    "        \n",
    "        self.lhs = Node(x = self.x, gradient= self.gradient, hessian = self.hessian, idxs = self.idxs[lhs],\n",
    "                        min_leaf= self.min_leaf, depth = self.depth - 1, lambda_= self.lambda_, \n",
    "                        min_child_weight = self.min_child_weight, eps = self.eps, \n",
    "                        subsample_cols = self.subsample_cols)\n",
    "        \n",
    "        self.rhs = Node(x = self.x, gradient= self.gradient, hessian = self.hessian, idxs = self.idxs[rhs],\n",
    "                        min_leaf= self.min_leaf, depth = self.depth - 1, lambda_= self.lambda_, \n",
    "                        min_child_weight = self.min_child_weight, eps = self.eps, \n",
    "                        subsample_cols = self.subsample_cols)\n",
    "    \n",
    "    def find_greedy_split(self,col):\n",
    "        # For the given attribute 'col' we try to calculate the best possible split.\n",
    "        # Globally updates the best score and split point if a better split point is found.\n",
    "        \n",
    "        x = self.x.values[self.idxs, col]   # returns numpy array of values of 'col' at certain indices\n",
    "        \n",
    "        \n",
    "        for r in range(0,self.rows_cnt):\n",
    "            lhs = x <= x[r]\n",
    "            rhs = x > x[r]\n",
    "            \n",
    "            lhs_indices = np.nonzero(x <= x[r])[0]            \n",
    "            rhs_indices = np.nonzero(x > x[r])[0]\n",
    "            \n",
    "            if(len(lhs_indices) < self.min_leaf or len(rhs_indices) < self.min_leaf or\n",
    "               self.hessian[self.idxs][lhs_indices].sum() < self.min_child_weight or \n",
    "               self.hessian[self.idxs][rhs_indices].sum() < self.min_child_weight):\n",
    "                continue\n",
    "            \n",
    "            poss_score = self.gain(lhs_indices,rhs_indices)\n",
    "            \n",
    "            if poss_score > self.score:\n",
    "                # print(col)\n",
    "                self.col = col\n",
    "                self.score = poss_score\n",
    "                self.split = x[r]\n",
    "    \n",
    "    def find_approx_split(self, col):\n",
    "        x = self.x.values[self.idxs, col]\n",
    "        hessian_ = self.hessian[self.idxs]\n",
    "        df = pd.DataFrame({'Feature': x, 'hess': hessian_, 'id': list(range(len(self.idxs)))})\n",
    "        df.sort_values(by=['Feature'], ascending=True, inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        hess_sum = df['hess'].sum()\n",
    "        df['rank'] = df.apply(lambda x: (sum(df[df['Feature'] <= x['Feature']]['hess'])) / hess_sum, axis=1)\n",
    "\n",
    "        prev_idx = 0\n",
    "        bins_done = 0\n",
    "        prev_rank = 0\n",
    "        total_bins = int(1 / self.eps)\n",
    "\n",
    "        for i in range(0, len(df)):\n",
    "            if (np.abs(df.loc[i, 'rank'] - prev_rank) >= self.eps):\n",
    "                new_df = df[prev_idx:i]\n",
    "                new_df.reset_index(inplace=True)\n",
    "                prev_idx = i\n",
    "                bins_done += 1\n",
    "                self.solve_bin(new_df,col)\n",
    "\n",
    "            if (bins_done >= total_bins - 1):\n",
    "                new_df = df[prev_idx:]\n",
    "                new_df.reset_index(inplace=True)\n",
    "                self.solve_bin(new_df,col)\n",
    "                break\n",
    "                \n",
    "\n",
    "\n",
    "    def solve_bin(self, df, col):\n",
    "        for r in range(0, len(df)):\n",
    "            split = df.loc[r,'Feature']\n",
    "\n",
    "            lhs = df['Feature'] <= df.loc[r, 'Feature']\n",
    "            lhs_indices = df.loc[lhs, 'id'].tolist()\n",
    "            \n",
    "            rhs = df['Feature'] > df.loc[r, 'Feature']\n",
    "            rhs_indices = df.loc[rhs, 'id'].tolist()\n",
    "            \n",
    "            \n",
    "            if (len(lhs_indices) < self.min_leaf or len(rhs_indices) < self.min_leaf or\n",
    "                    self.hessian[self.idxs][lhs_indices].sum() < self.min_child_weight or\n",
    "                    self.hessian[self.idxs][rhs_indices].sum() < self.min_child_weight):\n",
    "                continue\n",
    "\n",
    "            poss_score = self.gain(lhs_indices, rhs_indices)\n",
    "\n",
    "            if poss_score > self.score:\n",
    "                self.col = col\n",
    "                self.score = poss_score\n",
    "                self.split = split\n",
    "\n",
    "                    \n",
    "    \n",
    "    def gain(self,lhs,rhs):\n",
    "        # Calculates the gain for a particular split.\n",
    "        gradient = self.gradient[self.idxs]        \n",
    "        hessian = self.hessian[self.idxs]        \n",
    "        \n",
    "        lhs_gradient = gradient[lhs].sum()\n",
    "        lhs_hessian = hessian[lhs].sum()\n",
    "        \n",
    "        rhs_gradient = gradient[rhs].sum()\n",
    "        rhs_hessian = hessian[rhs].sum()\n",
    "        \n",
    "        gain = 0.5*((lhs_gradient**2)/(lhs_hessian+self.lambda_) + (rhs_gradient**2)/(rhs_hessian+self.lambda_)-\n",
    "                    ((gradient.sum())**2)/(hessian.sum()+self.lambda_)) - self.gamma\n",
    "        \n",
    "        return gain\n",
    "    \n",
    "    def split_col(self):    # Return values of a particular column\n",
    "        return self.x.values[self.idxs, self.col]\n",
    "    \n",
    "    def is_leaf(self):      # Check if node is leaf or not\n",
    "        # print(str(self.score) + \" \" +str(self.depth))\n",
    "        return self.score == float('-inf') or self.depth <=0 or len(self.x) == 1\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return np.array([self.predict_val(xi) for xi in x])\n",
    "    \n",
    "    def predict_val(self,xi):\n",
    "        # print(xi)\n",
    "        if (self.is_leaf()):\n",
    "            return self.val\n",
    "        \n",
    "        node = self.lhs if xi[self.col] <= self.split else self.rhs\n",
    "        \n",
    "        return node.predict_val(xi)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTree:\n",
    "    def fit(self,x,gradient,hessian,subsample_cols = 1, min_leaf = 1, min_child_weight = 1, \n",
    "            depth = 7, lambda_ = 1, gamma = 1, eps = 0.01):\n",
    "        self.root = Node(x, gradient, hessian, np.array(np.arange(len(x))), subsample_cols, min_leaf, min_child_weight,\n",
    "                         depth, lambda_, gamma, eps)\n",
    "    def predict(self,X):\n",
    "        return self.root.predict(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trees = []\n",
    "        self.learning_rates = []\n",
    "    \n",
    "    def gradient(self,prediction, actual):\n",
    "        return (2*(prediction-actual))\n",
    "    \n",
    "    def hessian(self,prediction, actual):\n",
    "        return (np.full((prediction.shape[0],),2).astype('float'))\n",
    "    \n",
    "    def fit(self, X, Y, subsample_cols = 1, min_leaf = 1, min_child_weight = 1, \n",
    "            depth = 5, lambda_ = 1, gamma = 1, eps = 0.01, learning_rate = 0.4, boosting_rounds = 5):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.subsample_cols = subsample_cols\n",
    "        self.min_leaf = min_leaf\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.depth = depth\n",
    "        self.lambda_ = lambda_\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.boosting_rounds = boosting_rounds\n",
    "        \n",
    "        self.prediction = np.full((X.shape[0],1),np.mean(Y)).flatten().astype('float')\n",
    "        \n",
    "        # print(self.prediction)\n",
    "        \n",
    "        for booster in range(0,self.boosting_rounds):\n",
    "            Gradient = self.gradient(np.array(self.prediction), np.array(self.Y))\n",
    "            Hessian = self.hessian(np.array(self.prediction), np.array(self.Y))\n",
    "            boosting_tree = XGBoostTree()\n",
    "            boosting_tree.fit(  self.X, Gradient,Hessian, self.subsample_cols, self.min_leaf,\n",
    "                                self.min_child_weight,self.depth,self.lambda_, self.gamma,\n",
    "                                self.eps)\n",
    "            \n",
    "            new_val = boosting_tree.predict(self.X)\n",
    "            new_learning_rate = self.Adam(self.Y, self.prediction, new_val)\n",
    "            self.prediction = self.prediction + new_learning_rate*(boosting_tree.predict(self.X))\n",
    "            self.trees.append(boosting_tree)\n",
    "            self.learning_rates.append(new_learning_rate)\n",
    "            print(\"Iteration: \"+ str(booster) + \" RMSE Score = \" +str(np.sqrt(np.mean((self.predict(self.X) - self.Y)**2))))\n",
    "    \n",
    "    def predict(self,X):\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        for i in range(len(self.trees)):\n",
    "            pred += self.learning_rates[i]*self.trees[i].predict(X)\n",
    "        return np.full((X.shape[0],),np.mean(self.Y)).astype('float') + pred\n",
    "    \n",
    "    \n",
    "    def AdamLoss(self, old_res, alpha, new_val):\n",
    "        return -2*np.sum(new_val*(old_res-alpha*new_val))\n",
    "    \n",
    "    def Adam(self, Y, base_pred, new_val):\n",
    "        old_res = Y - base_pred\n",
    "        print(old_res)\n",
    "        loss = 0\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.99\n",
    "        epsilon = 1e-18\n",
    "        eta = 0.001\n",
    "        m_old = 0\n",
    "        v_old = 0\n",
    "        mt = 0\n",
    "        vt = 0\n",
    "        mt_hat = 0\n",
    "        vt_hat = 0\n",
    "        t = 0\n",
    "        converged = False\n",
    "        alpha_old = self.learning_rate\n",
    "        alpha = self.learning_rate\n",
    "        while not converged:\n",
    "            t = t+1\n",
    "            loss = self.AdamLoss(old_res=old_res, alpha=alpha, new_val=new_val)\n",
    "            mt = beta1*m_old + (1-beta1)*loss\n",
    "            vt = beta2*v_old + (1-beta2)*loss\n",
    "            mt_hat = mt/(1-(beta1 ** t))\n",
    "            vt_hat = vt/(1-(beta2 ** t))\n",
    "            alpha = alpha_old - (eta*mt_hat)/(math.sqrt(max(vt_hat,epsilon)) + epsilon)\n",
    "            \n",
    "            if alpha_old == alpha:\n",
    "                converged = True \n",
    "            \n",
    "            alpha_old = alpha\n",
    "            m_old = mt\n",
    "            v_old = vt\n",
    "            \n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.5  7.5  8.5 -6.5]\n",
      "Iteration: 0 RMSE Score = 2.2082846689970383e-13\n",
      "[ 2.59348099e-13 -2.05169215e-13 -2.32702746e-13  1.77635684e-13]\n",
      "Iteration: 1 RMSE Score = 1.6185208837122475e-13\n",
      "[ 1.90070182e-13 -1.50102153e-13 -1.70530257e-13  1.30562228e-13]\n",
      "Iteration: 2 RMSE Score = 1.1831123320395927e-13\n",
      "[ 1.38555833e-13 -1.10134124e-13 -1.24344979e-13  9.59232693e-14]\n",
      "Iteration: 3 RMSE Score = 8.648003129016434e-14\n",
      "[ 1.01252340e-13 -8.08242362e-14 -9.05941988e-14  7.01660952e-14]\n",
      "Iteration: 4 RMSE Score = 6.340530252457267e-14\n",
      "[ 7.46069873e-14 -5.95079541e-14 -6.57252031e-14  5.15143483e-14]\n",
      "Iteration: 5 RMSE Score = 4.6597635579724805e-14\n",
      "[ 5.50670620e-14 -4.35207426e-14 -4.79616347e-14  3.81916720e-14]\n",
      "Iteration: 6 RMSE Score = 3.450204495357495e-14\n",
      "[ 4.08562073e-14 -3.19744231e-14 -3.55271368e-14  2.84217094e-14]\n",
      "Iteration: 7 RMSE Score = 2.5359788109947406e-14\n",
      "[ 3.01980663e-14 -2.30926389e-14 -2.66453526e-14  2.04281037e-14]\n",
      "Iteration: 8 RMSE Score = 1.8364041956551464e-14\n"
     ]
    }
   ],
   "source": [
    "data = {'Dosage':[10,20,25,37],\n",
    "        'Level' : [10,20,25,37]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "test_data = {'Dosage':[10,20,25,37],\n",
    "             'Level' : [10,20,25,37]}\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "Y = [-10,7,8,-7]\n",
    "model = XGBoostRegression()\n",
    "model.fit(df,Y,boosting_rounds = 9,gamma = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.,   7.,   8.,  -7.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframe.pickle', 'rb') as f:\n",
    "    new_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'PJME_MW', 'Lag1', 'Lag2', 'Hour_sin', 'Hour_cos',\n",
       "       'Day_sin', 'Day_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns=['PJME_MW','Datetime'])\n",
    "Y = new_df['PJME_MW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27077.0</td>\n",
       "      <td>25591.0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25957.0</td>\n",
       "      <td>24235.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24930.0</td>\n",
       "      <td>23121.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24359.0</td>\n",
       "      <td>22445.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24400.0</td>\n",
       "      <td>22332.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127745</th>\n",
       "      <td>31448.0</td>\n",
       "      <td>32878.0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.716633e-02</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127746</th>\n",
       "      <td>31246.0</td>\n",
       "      <td>32586.0</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.716633e-02</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127747</th>\n",
       "      <td>30526.0</td>\n",
       "      <td>31877.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.716633e-02</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127748</th>\n",
       "      <td>29209.0</td>\n",
       "      <td>30590.0</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.716633e-02</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127749</th>\n",
       "      <td>27617.0</td>\n",
       "      <td>29036.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.432760e-02</td>\n",
       "      <td>0.999411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127750 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Lag1     Lag2  Hour_sin  Hour_cos       Day_sin   Day_cos\n",
       "0       27077.0  25591.0  0.258819  0.965926 -2.449294e-16  1.000000\n",
       "1       25957.0  24235.0  0.500000  0.866025 -2.449294e-16  1.000000\n",
       "2       24930.0  23121.0  0.707107  0.707107 -2.449294e-16  1.000000\n",
       "3       24359.0  22445.0  0.866025  0.500000 -2.449294e-16  1.000000\n",
       "4       24400.0  22332.0  0.965926  0.258819 -2.449294e-16  1.000000\n",
       "...         ...      ...       ...       ...           ...       ...\n",
       "127745  31448.0  32878.0 -0.866025  0.500000  1.716633e-02  0.999853\n",
       "127746  31246.0  32586.0 -0.707107  0.707107  1.716633e-02  0.999853\n",
       "127747  30526.0  31877.0 -0.500000  0.866025  1.716633e-02  0.999853\n",
       "127748  29209.0  30590.0 -0.258819  0.965926  1.716633e-02  0.999853\n",
       "127749  27617.0  29036.0  0.000000  1.000000  3.432760e-02  0.999411\n",
       "\n",
       "[127750 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         27160.0\n",
       "1         25791.0\n",
       "2         25052.0\n",
       "3         24797.0\n",
       "4         25026.0\n",
       "           ...   \n",
       "127745    44284.0\n",
       "127746    43751.0\n",
       "127747    42402.0\n",
       "127748    40164.0\n",
       "127749    38608.0\n",
       "Name: PJME_MW, Length: 127750, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         -4988.386935\n",
      "1         -6357.386935\n",
      "2         -7096.386935\n",
      "3         -7351.386935\n",
      "4         -7122.386935\n",
      "              ...     \n",
      "127745    12135.613065\n",
      "127746    11602.613065\n",
      "127747    10253.613065\n",
      "127748     8015.613065\n",
      "127749     6459.613065\n",
      "Name: PJME_MW, Length: 127750, dtype: float64\n",
      "Iteration: 0 RMSE Score = 4124.297620510072\n",
      "0          -757.185879\n",
      "1          1194.646155\n",
      "2           455.646155\n",
      "3           200.646155\n",
      "4           429.646155\n",
      "              ...     \n",
      "127745    12578.189534\n",
      "127746    12045.189534\n",
      "127747    10696.189534\n",
      "127748    10321.093333\n",
      "127749     8765.093333\n",
      "Name: PJME_MW, Length: 127750, dtype: float64\n",
      "Iteration: 1 RMSE Score = 3990.5102490982986\n",
      "0         -1480.210149\n",
      "1           471.621885\n",
      "2          -267.378115\n",
      "3          -522.378115\n",
      "4          -293.378115\n",
      "              ...     \n",
      "127745    11407.297355\n",
      "127746    12040.914712\n",
      "127747    10691.914712\n",
      "127748     9598.069062\n",
      "127749     8042.069062\n",
      "Name: PJME_MW, Length: 127750, dtype: float64\n",
      "Iteration: 2 RMSE Score = 3881.8258040362234\n",
      "0         -1724.400816\n",
      "1           227.431218\n",
      "2          -511.568782\n",
      "3           -79.111787\n",
      "4           149.888213\n",
      "              ...     \n",
      "127745    11163.106688\n",
      "127746    11796.724045\n",
      "127747    10447.724045\n",
      "127748     9353.878395\n",
      "127749     7797.878395\n",
      "Name: PJME_MW, Length: 127750, dtype: float64\n",
      "Iteration: 3 RMSE Score = 3793.2408607725533\n",
      "0        -1304.084202\n",
      "1         -223.669247\n",
      "2         -962.669247\n",
      "3         -530.212252\n",
      "4         -301.212252\n",
      "             ...     \n",
      "127745    9228.846306\n",
      "127746    9862.463663\n",
      "127747    8513.463663\n",
      "127748    9774.195010\n",
      "127749    8218.195010\n",
      "Name: PJME_MW, Length: 127750, dtype: float64\n",
      "Iteration: 4 RMSE Score = 3745.7903583495226\n",
      "0        -1281.339783\n",
      "1         -521.013402\n",
      "2        -1260.013402\n",
      "3         -827.556408\n",
      "4         -598.556408\n",
      "             ...     \n",
      "127745    9251.590725\n",
      "127746    9885.208082\n",
      "127747    8536.208082\n",
      "127748    9796.939429\n",
      "127749    8240.939429\n",
      "Name: PJME_MW, Length: 127750, dtype: float64\n",
      "Iteration: 5 RMSE Score = 3708.9374796845045\n"
     ]
    }
   ],
   "source": [
    "model = XGBoostRegression()\n",
    "model.fit(X,Y,min_leaf = 5,min_child_weight = 5,boosting_rounds = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
